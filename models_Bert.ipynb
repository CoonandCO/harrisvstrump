{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0y57YyrYZKOb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "#from assnat.params import *\n",
        "#from assnat.clean import complete_preproc\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k80nGwWOZXsU",
        "outputId": "ac259e16-26c0-473e-9ff8-329ac4834282"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_Bu2wrZKOk",
        "outputId": "8c4cc230-84e2-41c6-d0ce-404a3e9209aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2026, 19204, 17629, 2015, 1998, 2944, 2442, 2674, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", padding_side = \"right\")\n",
        "tokenizer(\"My tokenizers and model must match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ooZm65ZKOn",
        "outputId": "f50e3bc2-59d5-4294-fa5b-f8ebdae032d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 corresponds to [CLS]\n",
            "2026 corresponds to my\n",
            "2944 corresponds to model\n",
            "1998 corresponds to and\n",
            "2026 corresponds to my\n",
            "19204 corresponds to token\n",
            "17629 corresponds to ##izer\n",
            "2442 corresponds to must\n",
            "2674 corresponds to match\n",
            "102 corresponds to [SEP]\n"
          ]
        }
      ],
      "source": [
        "# $CHALLENGIFY_BEGIN\n",
        "tokens = tokenizer(\"My model and my tokenizer must match\")[\"input_ids\"]\n",
        "\n",
        "for x in tokens:\n",
        "    print(f\"{x} corresponds to {tokenizer.decode(x)}\")\n",
        "# $CHALLENGIFY_END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoNOVd9qZKOq",
        "outputId": "756c5da9-3146-4d67-a4d4-398775386fd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((131558,), 131558)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Chargement et prétraitement des données\n",
        "leg_ = '/content/drive/MyDrive/Le Wagon/Project AssNat/leg16_preproc.csv'\n",
        "min_words_=10\n",
        "\n",
        "df_preproc = pd.read_csv(leg_)\n",
        "#df_preproc = complete_preproc(df, na_col=[\"Texte\", \"famille\"], drop_names=[\"Mme la présidente\", \"M. le président\"], min_words=min_words_, punct_opt=True)\n",
        "#df_preproc.to_csv('data/leg16_preproc.csv', index=False)\n",
        "\n",
        "X = df_preproc['Texte']  # Les textes à classifier\n",
        "y = df_preproc['famille']\n",
        "\n",
        "# Encodage des labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "X.shape, len(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "CkpEirxyZKOw",
        "outputId": "b8918596-6218-4ee4-a566-a9e442adf7db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vous nous ressortez votre intention de plafonner la production d’énergie nucléaire à 50\\xa0 comme si ce chiffre avait été gravé par moïse sur les tables de la loi alors que nous savons tous désormais qu’il a été griffonné sur un coin de table par françois hollande\\xa0!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vhaWHu05ZKO5",
        "outputId": "76e117b5-dc7c-4f7b-8d16-908d2fe1a5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 corresponds to <s>\n",
            "39 corresponds to vous\n",
            "63 corresponds to nous\n",
            "4008 corresponds to ressort\n",
            "267 corresponds to ez\n",
            "75 corresponds to votre\n",
            "7611 corresponds to intention\n",
            "8 corresponds to de\n",
            "8697 corresponds to pla\n",
            "362 corresponds to f\n",
            "11305 corresponds to onner\n",
            "13 corresponds to la\n",
            "844 corresponds to production\n",
            "18 corresponds to d\n",
            "12 corresponds to ’\n",
            "1214 corresponds to énergie\n",
            "4867 corresponds to nucléaire\n",
            "15 corresponds to à\n",
            "712 corresponds to 50\n",
            "79 corresponds to comme\n",
            "86 corresponds to si\n",
            "44 corresponds to ce\n",
            "2587 corresponds to chiffre\n",
            "171 corresponds to avait\n",
            "101 corresponds to été\n",
            "16734 corresponds to gravé\n",
            "37 corresponds to par\n",
            "115 corresponds to m\n",
            "8793 corresponds to oï\n",
            "10 corresponds to s\n",
            "35 corresponds to e\n",
            "32 corresponds to sur\n",
            "19 corresponds to les\n",
            "5630 corresponds to tables\n",
            "8 corresponds to de\n",
            "13 corresponds to la\n",
            "589 corresponds to loi\n",
            "183 corresponds to alors\n",
            "27 corresponds to que\n",
            "63 corresponds to nous\n",
            "6131 corresponds to savons\n",
            "117 corresponds to tous\n",
            "1085 corresponds to désormais\n",
            "46 corresponds to qu\n",
            "12 corresponds to ’\n",
            "62 corresponds to il\n",
            "33 corresponds to a\n",
            "101 corresponds to été\n",
            "21 corresponds to \n",
            "21470 corresponds to griff\n",
            "9804 corresponds to onné\n",
            "32 corresponds to sur\n",
            "23 corresponds to un\n",
            "1719 corresponds to coin\n",
            "8 corresponds to de\n",
            "847 corresponds to table\n",
            "37 corresponds to par\n",
            "9871 corresponds to fran\n",
            "14292 corresponds to çois\n",
            "13033 corresponds to hol\n",
            "10779 corresponds to lande\n",
            "83 corresponds to !\n",
            "6 corresponds to </s>\n"
          ]
        }
      ],
      "source": [
        "# $CHALLENGIFY_BEGIN\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"almanach/camembert-base\", padding_side = \"right\")\n",
        "\n",
        "tokens = tokenizer(X[100])[\"input_ids\"]\n",
        "\n",
        "for x in tokens:\n",
        "    print(f\"{x} corresponds to {tokenizer.decode(x)}\")\n",
        "# $CHALLENGIFY_END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pttVe5bGZKO_",
        "outputId": "9d75228a-905f-4070-fc38-e87e6736103f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFCamembertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFCamembertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFCamembertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# $CHALLENGIFY_BEGIN\n",
        "from transformers import TFAutoModel\n",
        "model = TFAutoModel.from_pretrained(\"almanach/camembert-base\", from_pt = True)\n",
        "# $CHALLENGIFY_END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CekDMnitZKPG",
        "outputId": "df879dc1-1b69-4926-f66c-cd18b13ad84a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110621952"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5VcCRyfZKPJ",
        "outputId": "520fcdb1-70ba-4963-8686-87f5a8867b8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 63), dtype=int32, numpy=\n",
              "array([[    5,    39,    63,  4008,   267,    75,  7611,     8,  8697,\n",
              "          362, 11305,    13,   844,    18,    12,  1214,  4867,    15,\n",
              "          712,    79,    86,    44,  2587,   171,   101, 16734,    37,\n",
              "          115,  8793,    10,    35,    32,    19,  5630,     8,    13,\n",
              "          589,   183,    27,    63,  6131,   117,  1085,    46,    12,\n",
              "           62,    33,   101,    21, 21470,  9804,    32,    23,  1719,\n",
              "            8,   847,    37,  9871, 14292, 13033, 10779,    83,     6]],\n",
              "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 63), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
              "      dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tensor_token = tokenizer(X[100], return_tensors=\"tf\")\n",
        "tensor_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "b7QaTvMsZKPN",
        "outputId": "3b01d24e-4e24-4500-8792-66abf06ac258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_preproc[\"tokenized\"] = X.map(lambda x: tokenizer(x)[\"input_ids\"])\n",
        "\n",
        "df_preproc[\"len_tokenized\"] = X.map(lambda x: len(x))\n",
        "\n",
        "df_preproc[\"len_tokenized\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8_gn-sE6ZKPR"
      },
      "outputs": [],
      "source": [
        "sample_size = 50_000\n",
        "# $CHALLENGIFY_BEGIN\n",
        "tokenized_tensors = tokenizer(X[0:sample_size].tolist(), max_length=50, padding = \"max_length\", truncation = True, return_tensors=\"tf\")\n",
        "# $CHALLENGIFY_END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsyPJk9rZKPT",
        "outputId": "cae5b2b1-b019-4dbe-fb63-84d51a06227f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([50000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenized_tensors.input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sI7vedPLZKPX",
        "outputId": "a87760eb-bbd2-4673-dce3-81c75f3ebcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 21s 104ms/step\n",
            "32/32 [==============================] - 3s 99ms/step\n",
            "32/32 [==============================] - 4s 109ms/step\n",
            "32/32 [==============================] - 3s 100ms/step\n",
            "32/32 [==============================] - 3s 101ms/step\n",
            "32/32 [==============================] - 3s 108ms/step\n",
            "32/32 [==============================] - 3s 102ms/step\n",
            "32/32 [==============================] - 3s 102ms/step\n",
            "32/32 [==============================] - 4s 109ms/step\n",
            "32/32 [==============================] - 3s 103ms/step\n",
            "32/32 [==============================] - 3s 105ms/step\n",
            "32/32 [==============================] - 3s 109ms/step\n",
            "32/32 [==============================] - 3s 104ms/step\n",
            "32/32 [==============================] - 3s 104ms/step\n",
            "32/32 [==============================] - 3s 108ms/step\n",
            "32/32 [==============================] - 3s 106ms/step\n",
            "32/32 [==============================] - 3s 105ms/step\n",
            "32/32 [==============================] - 3s 105ms/step\n",
            "32/32 [==============================] - 4s 109ms/step\n",
            "32/32 [==============================] - 3s 106ms/step\n",
            "32/32 [==============================] - 3s 109ms/step\n",
            "32/32 [==============================] - 4s 110ms/step\n",
            "32/32 [==============================] - 3s 106ms/step\n",
            "32/32 [==============================] - 4s 111ms/step\n",
            " 3/32 [=>............................] - ETA: 3s"
          ]
        }
      ],
      "source": [
        "#embeddings = model.predict(tokenized_tensors[\"input_ids\"])\n",
        "\n",
        "# Process the data in smaller batches\n",
        "batch_size = 1000\n",
        "embeddings = []\n",
        "for i in range(0, sample_size, batch_size):\n",
        "  batch_tensors = {k: v[i:i+batch_size] for k, v in tokenized_tensors.items()}\n",
        "  batch_embeddings = model.predict(batch_tensors)\n",
        "  embeddings.append(batch_embeddings)\n",
        "\n",
        "# Concatenate the embeddings from all batches if necessary\n",
        "#embeddings = np.concatenate(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8HZI8e6B1iJX",
        "outputId": "44189f10-665d-4939-9d03-6539d1c922ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=array([[[ 0.0532216 ,  0.04991549,  0.11046399, ..., -0.10858352,\n",
              "           0.03737131,  0.0110695 ],\n",
              "         [ 0.07157509, -0.07916605,  0.19290379, ...,  0.04103548,\n",
              "           0.03665832,  0.00314926],\n",
              "         [ 0.01561674,  0.12426847,  0.09406845, ..., -0.12447979,\n",
              "          -0.07138827,  0.07295826],\n",
              "         ...,\n",
              "         [ 0.123538  , -0.42362577,  0.11867409, ..., -0.01154631,\n",
              "           0.041054  ,  0.05313954],\n",
              "         [ 0.10628709,  0.37706298,  0.03471091, ..., -0.05813523,\n",
              "           0.11697122,  0.08601236],\n",
              "         [ 0.00896472,  0.08237377,  0.12580268, ..., -0.0777267 ,\n",
              "          -0.00794687, -0.01098494]],\n",
              " \n",
              "        [[ 0.05736858, -0.11006886,  0.07004154, ..., -0.07074974,\n",
              "           0.00697316,  0.06330613],\n",
              "         [-0.04866023,  0.28864402,  0.15088011, ...,  0.06994712,\n",
              "           0.04030159,  0.10710827],\n",
              "         [-0.07784601,  0.03689325, -0.01827769, ..., -0.02139296,\n",
              "           0.05181033,  0.14055677],\n",
              "         ...,\n",
              "         [ 0.02034993, -0.06989737,  0.07907176, ..., -0.03112512,\n",
              "          -0.04380602,  0.04739895],\n",
              "         [ 0.02034993, -0.06989737,  0.07907176, ..., -0.03112512,\n",
              "          -0.04380602,  0.04739895],\n",
              "         [ 0.02034993, -0.06989737,  0.07907176, ..., -0.03112512,\n",
              "          -0.04380602,  0.04739895]],\n",
              " \n",
              "        [[ 0.02135194, -0.05891307,  0.02808395, ..., -0.10451698,\n",
              "           0.04919614,  0.03596553],\n",
              "         [ 0.00111724, -0.02288748,  0.04322194, ..., -0.02363774,\n",
              "           0.07864086, -0.1508222 ],\n",
              "         [ 0.07137436, -0.18015532, -0.22542343, ..., -0.03610825,\n",
              "           0.037115  ,  0.04565991],\n",
              "         ...,\n",
              "         [-0.10954594, -0.10158023,  0.02268139, ..., -0.1067723 ,\n",
              "          -0.10210858,  0.11351895],\n",
              "         [-0.00146068, -0.00801265, -0.22618026, ..., -0.06958187,\n",
              "           0.00538686,  0.10021645],\n",
              "         [-0.02734939, -0.02453272,  0.03180562, ..., -0.07706694,\n",
              "           0.00838983,  0.01174696]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.02487331, -0.06779603,  0.06453606, ..., -0.1053628 ,\n",
              "           0.0778389 , -0.00442046],\n",
              "         [ 0.03186761, -0.27131122,  0.10464491, ..., -0.26086038,\n",
              "          -0.05401535, -0.15595353],\n",
              "         [ 0.05238155, -0.1884061 ,  0.03651624, ..., -0.0614612 ,\n",
              "           0.16337658, -0.23862955],\n",
              "         ...,\n",
              "         [-0.07002265, -0.03396259,  0.0679676 , ..., -0.07842191,\n",
              "           0.04539336, -0.03289896],\n",
              "         [-0.07002265, -0.03396259,  0.0679676 , ..., -0.07842191,\n",
              "           0.04539336, -0.03289896],\n",
              "         [-0.07002265, -0.03396259,  0.0679676 , ..., -0.07842191,\n",
              "           0.04539336, -0.03289896]],\n",
              " \n",
              "        [[-0.00860552,  0.10444956,  0.03998009, ..., -0.13141225,\n",
              "          -0.01979291, -0.00364546],\n",
              "         [ 0.10334837, -0.03965063, -0.05235551, ..., -0.02201676,\n",
              "           0.03442438,  0.02119283],\n",
              "         [-0.00088036, -0.12675717, -0.10106473, ..., -0.18330525,\n",
              "          -0.02982865,  0.04778493],\n",
              "         ...,\n",
              "         [ 0.00606192,  0.24034746, -0.29072845, ..., -0.04158295,\n",
              "          -0.00880545,  0.17406794],\n",
              "         [ 0.03569432,  0.18192223, -0.03501453, ...,  0.05151912,\n",
              "           0.01075055, -0.04779617],\n",
              "         [-0.04907878,  0.15580514,  0.03834131, ..., -0.09768726,\n",
              "          -0.06079139, -0.03724881]],\n",
              " \n",
              "        [[ 0.0212105 ,  0.04755328,  0.03001979, ..., -0.06557034,\n",
              "           0.01952293,  0.02841308],\n",
              "         [ 0.03249073,  0.1740375 , -0.40085748, ...,  0.0421351 ,\n",
              "           0.01555254,  0.04643238],\n",
              "         [-0.10595375,  0.26550472,  0.00406113, ..., -0.02299628,\n",
              "           0.07513257,  0.15175001],\n",
              "         ...,\n",
              "         [-0.03961657,  0.09442513,  0.02692595, ..., -0.01272471,\n",
              "          -0.02704715,  0.00412332],\n",
              "         [-0.03961657,  0.09442513,  0.02692595, ..., -0.01272471,\n",
              "          -0.02704715,  0.00412332],\n",
              "         [-0.03961657,  0.09442513,  0.02692595, ..., -0.01272471,\n",
              "          -0.02704715,  0.00412332]]], dtype=float32), pooler_output=array([[-0.07433978,  0.08852832, -0.00400672, ...,  0.05046201,\n",
              "         -0.10965209,  0.04143032],\n",
              "        [-0.07649744,  0.06224899,  0.01935483, ...,  0.03014829,\n",
              "         -0.11957714,  0.03755145],\n",
              "        [-0.04815125,  0.04451448,  0.00651211, ...,  0.01831035,\n",
              "         -0.147596  ,  0.05560289],\n",
              "        ...,\n",
              "        [-0.08137242,  0.0583453 , -0.02054959, ...,  0.02433654,\n",
              "         -0.07695102,  0.05847681],\n",
              "        [-0.06086585,  0.04456967,  0.01188855, ...,  0.11928298,\n",
              "         -0.12670194,  0.01072192],\n",
              "        [-0.14568348,  0.08086155, -0.00464318, ...,  0.04065499,\n",
              "         -0.11723068,  0.09650225]], dtype=float32), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None),\n",
              " TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=array([[[ 0.04483908,  0.04328918,  0.03430964, ..., -0.14439446,\n",
              "           0.04424424,  0.01062281],\n",
              "         [-0.04738346,  0.3133289 ,  0.2579146 , ..., -0.05610059,\n",
              "          -0.07082489,  0.24289763],\n",
              "         [ 0.00126688, -0.08928005, -0.27491352, ..., -0.12585713,\n",
              "           0.08200982,  0.15451705],\n",
              "         ...,\n",
              "         [ 0.05003486,  0.05974296, -0.49386764, ..., -0.08814283,\n",
              "           0.10858117, -0.11722536],\n",
              "         [-0.08879015,  0.2793287 , -0.17885071, ..., -0.10662188,\n",
              "           0.13801949,  0.10666049],\n",
              "         [ 0.00231576,  0.085463  ,  0.0277855 , ..., -0.12013719,\n",
              "          -0.00411816, -0.02276722]],\n",
              " \n",
              "        [[ 0.00871863, -0.02516112,  0.10859923, ..., -0.06791779,\n",
              "           0.03839321,  0.00781761],\n",
              "         [ 0.10638979,  0.33907655, -0.08435805, ..., -0.0642237 ,\n",
              "          -0.01809631,  0.22202826],\n",
              "         [ 0.10035585, -0.01737774, -0.04287772, ..., -0.14929393,\n",
              "           0.13531378, -0.02669567],\n",
              "         ...,\n",
              "         [ 0.02837117,  0.32812747, -0.23575662, ..., -0.02329486,\n",
              "           0.00159357,  0.18441436],\n",
              "         [ 0.02837117,  0.32812747, -0.23575662, ..., -0.02329486,\n",
              "           0.00159357,  0.18441436],\n",
              "         [ 0.02837117,  0.32812747, -0.23575662, ..., -0.02329486,\n",
              "           0.00159357,  0.18441436]],\n",
              " \n",
              "        [[ 0.06523313, -0.02633296,  0.04987747, ..., -0.14623918,\n",
              "           0.02813127,  0.02951809],\n",
              "         [ 0.07835263, -0.18268164, -0.11681913, ..., -0.01036403,\n",
              "           0.16584481,  0.10024818],\n",
              "         [ 0.08123246,  0.2148315 ,  0.10772765, ..., -0.02161111,\n",
              "           0.06319219,  0.07561338],\n",
              "         ...,\n",
              "         [ 0.16979   , -0.09975082, -0.34392688, ..., -0.09999043,\n",
              "           0.08684029,  0.09213176],\n",
              "         [ 0.0216838 ,  0.02664876, -0.04723167, ..., -0.01307819,\n",
              "           0.05552889,  0.01700025],\n",
              "         [ 0.01228342,  0.01809513,  0.04988552, ..., -0.12149873,\n",
              "          -0.0220065 , -0.00138468]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.05983328,  0.05671162,  0.03659855, ..., -0.0751832 ,\n",
              "           0.05272981,  0.06373084],\n",
              "         [ 0.14191964,  0.27861112,  0.10586599, ..., -0.08841212,\n",
              "           0.07172725,  0.23164393],\n",
              "         [ 0.02980347,  0.13635626, -0.03334922, ..., -0.05782612,\n",
              "           0.04238349,  0.20577936],\n",
              "         ...,\n",
              "         [ 0.00850166,  0.05830748, -0.45316964, ..., -0.07194394,\n",
              "           0.09477127,  0.21615276],\n",
              "         [ 0.02899504,  0.02044341, -0.17199634, ...,  0.02703154,\n",
              "           0.1563996 ,  0.05516867],\n",
              "         [ 0.01577008,  0.10808557,  0.03240171, ..., -0.04294326,\n",
              "           0.02027661,  0.03186438]],\n",
              " \n",
              "        [[-0.02861586,  0.05287208, -0.01784402, ..., -0.09124933,\n",
              "           0.05477145,  0.02236546],\n",
              "         [ 0.15494335,  0.2394109 ,  0.24361303, ..., -0.13562605,\n",
              "          -0.07938208,  0.1405627 ],\n",
              "         [ 0.28735924,  0.2769422 ,  0.25038645, ..., -0.02328938,\n",
              "           0.12608649, -0.13028058],\n",
              "         ...,\n",
              "         [-0.07829925,  0.09584151, -0.03473178, ..., -0.06156958,\n",
              "           0.00189721,  0.0019331 ],\n",
              "         [-0.07829925,  0.09584151, -0.03473178, ..., -0.06156958,\n",
              "           0.00189721,  0.0019331 ],\n",
              "         [-0.07829925,  0.09584151, -0.03473178, ..., -0.06156958,\n",
              "           0.00189721,  0.0019331 ]],\n",
              " \n",
              "        [[ 0.03323184,  0.13777627, -0.03452937, ..., -0.03664967,\n",
              "           0.08660566,  0.00784921],\n",
              "         [ 0.05203931,  0.13283923, -0.15874183, ..., -0.06943506,\n",
              "           0.04546727,  0.08830115],\n",
              "         [ 0.20159279,  0.02801937,  0.04471253, ...,  0.05454802,\n",
              "           0.13819303, -0.06899081],\n",
              "         ...,\n",
              "         [-0.0049267 ,  0.17510301, -0.04907472, ..., -0.00429958,\n",
              "           0.03274709, -0.02639217],\n",
              "         [-0.0049267 ,  0.17510301, -0.04907472, ..., -0.00429958,\n",
              "           0.03274709, -0.02639217],\n",
              "         [-0.0049267 ,  0.17510301, -0.04907472, ..., -0.00429958,\n",
              "           0.03274709, -0.02639217]]], dtype=float32), pooler_output=array([[-0.01517555,  0.05864866, -0.00060938, ...,  0.07882948,\n",
              "         -0.11688048,  0.00779472],\n",
              "        [-0.0735795 ,  0.0863134 , -0.01909088, ...,  0.02795462,\n",
              "         -0.1495263 ,  0.05973272],\n",
              "        [-0.06674932,  0.02853097,  0.00374332, ...,  0.05651541,\n",
              "         -0.13654743,  0.05362456],\n",
              "        ...,\n",
              "        [-0.03421518,  0.06984394, -0.03278867, ...,  0.02755701,\n",
              "         -0.12318629,  0.06702678],\n",
              "        [-0.05165928,  0.05359555,  0.02092892, ...,  0.04707184,\n",
              "         -0.09728986,  0.01324126],\n",
              "        [-0.07897455,  0.03589252, -0.00369841, ...,  0.0411762 ,\n",
              "         -0.08382162,  0.03324045]], dtype=float32), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_all = np.concatenate([embeddings[x].last_hidden_state[:,0,:] for x in range(50)], axis=0)"
      ],
      "metadata": {
        "id": "kjgCcmHQxN5W"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754EftNJZKPY",
        "outputId": "0d03c181-255a-49f5-f051-d41db7ae5926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "embeddings_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kl_3UuANZKPZ"
      },
      "outputs": [],
      "source": [
        "#X_sample = embeddings.last_hidden_state[:,0,:]\n",
        "X_sample = embeddings_all\n",
        "y_sample = y_encoded[0:sample_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmHbNxU8ZKPZ",
        "outputId": "1e943202-9c83-4fb2-db50-30e9a02a8547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 768), (10000, 768), (40000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9n-33gWZKPa",
        "outputId": "68d30f95-37cf-4bb0-de7e-f127057e69e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 256)               196864    \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198920 (777.03 KB)\n",
            "Trainable params: 198920 (777.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# $CHALLENGIFY_BEGIN\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "input_shape = (768,)\n",
        "\n",
        "dense_model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=input_shape),\n",
        "    Flatten(),\n",
        "    Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "dense_model.summary()\n",
        "# $CHALLENGIFY_END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuz7dxoiZKPb",
        "outputId": "f81969f8-a39c-41ca-c610-822db3199cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 6s 3ms/step - loss: 1.7675 - accuracy: 0.3333 - val_loss: 1.7547 - val_accuracy: 0.3325\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7259 - accuracy: 0.3422 - val_loss: 1.7219 - val_accuracy: 0.3392\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7059 - accuracy: 0.3483 - val_loss: 1.7199 - val_accuracy: 0.3430\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6941 - accuracy: 0.3542 - val_loss: 1.7068 - val_accuracy: 0.3462\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6828 - accuracy: 0.3531 - val_loss: 1.7034 - val_accuracy: 0.3455\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6736 - accuracy: 0.3594 - val_loss: 1.7036 - val_accuracy: 0.3496\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6655 - accuracy: 0.3610 - val_loss: 1.7061 - val_accuracy: 0.3465\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6557 - accuracy: 0.3632 - val_loss: 1.6946 - val_accuracy: 0.3486\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6495 - accuracy: 0.3681 - val_loss: 1.6911 - val_accuracy: 0.3466\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6405 - accuracy: 0.3713 - val_loss: 1.6854 - val_accuracy: 0.3531\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6331 - accuracy: 0.3734 - val_loss: 1.6856 - val_accuracy: 0.3515\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6254 - accuracy: 0.3745 - val_loss: 1.7012 - val_accuracy: 0.3396\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6200 - accuracy: 0.3794 - val_loss: 1.6848 - val_accuracy: 0.3569\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6111 - accuracy: 0.3833 - val_loss: 1.6865 - val_accuracy: 0.3551\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6023 - accuracy: 0.3844 - val_loss: 1.6951 - val_accuracy: 0.3486\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5948 - accuracy: 0.3877 - val_loss: 1.6882 - val_accuracy: 0.3530\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5875 - accuracy: 0.3920 - val_loss: 1.6905 - val_accuracy: 0.3495\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5810 - accuracy: 0.3954 - val_loss: 1.6981 - val_accuracy: 0.3385\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6903 - accuracy: 0.3591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6902846097946167, 0.35910001397132874]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "patience_ = 5\n",
        "epoch_=100\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=patience_, restore_best_weights=True)\n",
        "\n",
        "dense_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "dense_model.fit(X_train, y_train, validation_split=0.2, epochs=epoch_, batch_size=32, callbacks=[early_stopper])\n",
        "\n",
        "dense_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédire sur l'ensemble de test\n",
        "y_pred = dense_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "print(\"Rapport de classification pour le Dense avec Bert:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojX5kSlI8AgG",
        "outputId": "b1537726-5b8d-4a46-d800-ecc1ec6540b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Rapport de classification pour le Dense avec Bert:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Centre       0.40      0.76      0.52      3191\n",
            "  Centre-droit       0.33      0.01      0.01       835\n",
            " Centre-gauche       0.41      0.02      0.04       366\n",
            "        Droite       0.29      0.04      0.07      1116\n",
            "Extrême droite       0.28      0.10      0.15       972\n",
            "Extrême gauche       0.33      0.36      0.34      1604\n",
            "        Gauche       0.27      0.25      0.26      1791\n",
            "      Variable       0.00      0.00      0.00       125\n",
            "\n",
            "      accuracy                           0.36     10000\n",
            "     macro avg       0.29      0.19      0.17     10000\n",
            "  weighted avg       0.33      0.36      0.29     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other structure"
      ],
      "metadata": {
        "id": "gBxy2OqR5c0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C011X9OYZKPb",
        "outputId": "e9d2bc9c-888f-4581-d38f-56df0130c0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_3 (Masking)         (None, 768, 50)           0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 768, 256)          13056     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 768, 8)            2056      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,112\n",
            "Trainable params: 15,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Construire le modèle RNN avec LSTM\n",
        "#embedding_dim = embedding_dim_\n",
        "input_shape = (768, 50)\n",
        "patience_ = 5\n",
        "epoch_=5\n",
        "\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=patience_, restore_best_weights=True)\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "model.add(Masking(input_shape=input_shape))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBskYABPZKPc",
        "outputId": "094b7ec8-c56c-41ba-de4b-e118b30c8ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 768, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 768, 50), dtype=tf.float32, name='masking_3_input'), name='masking_3_input', description=\"created by layer 'masking_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 50, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m epoch_\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Prédire sur l'ensemble de test\u001b[39;00m\n\u001b[1;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filesq6kx051.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/bouzelfi/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 50, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Entraîner le modèle\n",
        "batch_size = 64\n",
        "epochs = epoch_\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopper],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "print(\"Rapport de classification pour le Dense avec Bert:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cHINFLYZKPc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}